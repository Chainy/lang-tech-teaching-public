{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Style des gesamten Dokuments */\n",
       "#notebook-container {\n",
       "\tfont-family: \"NimbusMonL-ReguObli\";\n",
       "\tfont-size: 120%\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r die Ãœberschrift: Zentriert diese und stellt sie fett dar. */\n",
       ".headline {\n",
       "\ttext-align: center;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 185.7%\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r die Aufgabenbeschreibung. Z.B.: \"Ãœbung zum Thema...\" */\n",
       ".description {\n",
       "\ttext-align: center;\n",
       "\tfont-size: 145.7%\n",
       "}\n",
       "\n",
       "/* Hebt das Abgabedatum fett und kursiv hervor */\n",
       "#submission {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r das eigentliche Thema. Z.B.: \"Intelligenz\" */\n",
       "#topic {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       ".task_description {\n",
       "\tmargin-bottom: 20px;\n",
       "}\n",
       "\n",
       "/* Hebt die Aufgabennummerierung fett hervor. */\n",
       ".task {\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 120%;\n",
       "\tborder-bottom: 2px solid black;\n",
       "  background-color: #97CAEF;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 50px;\n",
       "  padding-right: 50px;\n",
       "}\n",
       "\n",
       ".subtask {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #CAFAFE;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 25px;\n",
       "  padding-right: 25px;\n",
       "}\n",
       "\n",
       ".l1 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #14A76C;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l2 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FFE400;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l3 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FF652F;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".points {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       "ol.lower_roman {\n",
       "    list-style-type: lower-roman;\n",
       "}\n",
       "\n",
       "ol.characters {\n",
       "    list-style-type: lower-alpha;\n",
       "}\n",
       "\n",
       "/* Style einer Code-Cell */\n",
       ".CodeMirror-code {\n",
       "\tbackground-color: #ededed\n",
       "}\n",
       "\n",
       "/* Style eines Kommentars im Code Ã¤ndern. */\n",
       ".cm-s-ipython span.cm-comment {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-atom {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-number {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Keywords Ã¤ndern */\n",
       ".cm-s-ipython span.cm-keyword {\n",
       "\tcolor: #B000B0\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-def {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Python-Variable Ã¤ndern */\n",
       ".cm-s-ipython span.cm-variable {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Property Ã¤ndern */\n",
       ".cm-s-ipython span.cm-property {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Operators Ã¤ndern */\n",
       ".cm-s-ipython span.cm-operator {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Strings Ã¤ndern */\n",
       ".cm-s-ipython span.cm-string {\n",
       "\tcolor: brown;\n",
       "}\n",
       "\n",
       "/* Style einer eingebauten Funktion Ã¤ndern (z.B. \"open\") */\n",
       ".cm-s-ipython span.cm-builtin {\n",
       "\n",
       "}\n",
       "\n",
       "/* Hebt hervor, welche Klammern zueinander passen */\n",
       ".cm-s-ipython .CodeMirror-matchingbracket {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-variable-2 {\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2020/2021\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"Word Sense Induction\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">Friday, 11.12.2020 (11:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Präsenzübung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import wordnet as wn  \n",
    "from nltk.book import text2,text3 \n",
    "from nltk.text import Text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "from sklearn.cluster import KMeans  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.1:</i> <br>\n",
    "</div>\n",
    "\n",
    "Stopword: Which of the following statements are true?\n",
    "\n",
    "1. A stopword is a word used to stop a parsing process.\n",
    "2. A stopword is a high-frequency word.\n",
    "3. Punctuation marks like ``.``, ``,``, and ``;`` are stop words.\n",
    "4. \"the, to, and\" are stop words.\n",
    "5. Stopwords have a maximum length of 3.\n",
    "6. NLTK offers a list of English stopwords through: nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.2:</i> <br>\n",
    "</div>\n",
    "\n",
    "Synset: Which of the following statements are true?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A synset is a set of words that are interchangeable in some context without changing the meaning of a sentence in which they are embedded.\n",
    "2. A synset is a set of all bigrams within wordnet.\n",
    "3. Within W ordnet (corpus / lexical ressource) each word corresponds to one or more synsets.\n",
    "4. You may access the synsets of \"dog\" in NLTK by using nltk.corpus.wordnet.synsets('dog')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.3:</i> <br>\n",
    "</div>\n",
    "There are two possible definitions of \"word\":\n",
    "\n",
    "* Word is the same as token, for example \"see\" and \"saw\" are different words;\n",
    "* Word is the same as lemma, hence \"things\" and \"thing\" becomes the same words. \n",
    "<br><br>Which of the following statements are true?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The lemma of \"appeared\" is \"appear\".\n",
    "2. The lemma of a verb is its infinitive.\n",
    "3. Two words having the same lemma are called homonyms.\n",
    "4. Each token has one and only one lemma.\n",
    "5. Each lemma belongs to one and only one word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.4:</i> <br>\n",
    "</div>\n",
    "\n",
    "A stopword list contains high-frequency words like \"the\", \"to\", \"and\", or \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. NLTK provides a predefined list of stopwords: nltk.corpus.stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.4.1</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "Find all non-stopwords in carroll-alice.txt of the corpus Gutenberg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.4.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "Implement a function is_the_same_vocab(text1,text2) that compares two texts. It should return true, if the texts have the same vocabulary after removing the stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.5:</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the code below for some examples on how to work with WordNet. You can also execute it on your computer to see how the output looks like for a better understanding.\n",
    "\n",
    "Explain the code line by line, what datatype and meaning have the methods used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wn.synsets('motorcar'), \"\\n\")\n",
    "print(wn.synset('car.n.01').lemma_names(), \"\\n\")\n",
    "print(wn.synset('car.n.01').definition(), \"\\n\")\n",
    "print(wn.synset('car.n.01').examples(), \"\\n\")  \n",
    "print(wn.synset('car.n.01').lemmas(), \"\\n\")\n",
    "print(wn.lemma('car.n.01.automobile'), \"\\n\")  \n",
    "print(wn.lemma('car.n.01.automobile').synset(), \"\\n\")\n",
    "print(wn.lemma('car.n.01.automobile').name(), \"\\n\")  \n",
    "print(wn.synsets('car'), \"\\n\")\n",
    "print(wn.lemmas('car'), \"\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.6:</i> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.6.1.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "List all the senses of the word \"like\" that you can think of. Now we want to see how many different meanings the word \"like\" has with the help of WordNet, using the same operations we used above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.6.2.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "As you can see above, the words can have different POS tags. Suppose you are only interested in the adjective \"warm\". Write a function that will output definitions and examples of the word \"warm\" under this condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.6.3.</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "Write functions that outputs the hypernyms and hyponyms of the word \"bank\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.6.4</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Another aspect we can examine is if a word has an antonym (word with opposite meaning). Write a function that searches an antonym for the word \"like\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.7:</i> <br>\n",
    "</div>\n",
    "The polysemy of a word is the number of senses it has. We now want to compute the average polysemy of nouns, verbs, adjectives and adverbs according to WordNet and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.7.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Try to think of an algorithm that caclulates the ploysemy of a POS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.7.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the code below. Implement it and enhance the main function so that the average polysemy is calculated not only for nouns but also for verbs, adjectives and adverbs (do not implement your algorithm yet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgPolysemy():\n",
    "    #TODO, return average polysemy\n",
    "    \n",
    "avgN = avgPolysemy()\n",
    "    #TODO\n",
    "\n",
    "print(\"average polysemy of nouns: \", + avgN)\n",
    "    #TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.7.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Now implement your algorithm and calculate the average polysemy for nouns, verbs, adjectives and adverbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.8:</i> <br>\n",
    "</div>\n",
    "\n",
    "A concordance view shows us every occurrence of a given word, together with some context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.8.1.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "Extract context samples of word \"affection\" in \"Sense and Sensibility\" (text2) corpus of nltk and word \"lived\" in \"Book of Genesis\" (text3) corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.8.2.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Similar words for the term can be found if words share same context as that of token. \n",
    "\n",
    "For example: monsterous occurred in contexts such as \"the monsterous pictures\" and \"a monsterous size\". What other words appear in a similar range of contexts? We can find out by appending the term similar to the name of the text in question, then inserting the relevant word in parentheses:\n",
    "\n",
    "Find out similar words for affection in \"Sense and Sensibility\" (text2) corpus of nltk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.10:</i> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are capable of capturing the meaning of words within a document. Explore the library gensim by training your own word embeddings and test pretrained word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.10.1.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "Import the common_text corpus from the gensim library and display the first 10 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.10.2.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "Train the Word2vec model based on gensim with the follwing parameters:\n",
    "    - Size of the dimension = 100\n",
    "    - Context window size = 5\n",
    "    - Minimum frequency count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.10.3.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Display the vector of the word \"computer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.10.4.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Compute the similarity score between the words \"graph\" and \"trees\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.10.5.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Calculate the top 5 most similar words to the word \"graph\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with pretrained google word2vec embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 5.11:</i> <br>\n",
    "</div>\n",
    "\n",
    "The Google word2vec embeddings were trained on Google news data (about 100 billion words); It contains 3 million words and phrases and was fit using 300-dimensional word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the GoogleNews-vectors-negative300.bin.gz embeddings in your current working directory and unzip it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a 1.53 Gigabytes file. You can download it from here:\n",
    "\n",
    "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.11.1.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Instantiate a gensim word2vec model using the pretrained embeddings from google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "google_word2vec_model = #TODO#load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.11.2.</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "The operation *(king – man) + woman = ?* can be performed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_word2vec_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate: *(Germany – Berlin) + Moscow = ?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Submission guidelines*\n",
    "* *The submission has to be done by a team of two people. **Individual submissions will not be graded**.*\n",
    "* *Please state the **name and matriculation number of all team members** in every submission **clearly**.*\n",
    "* *Only **one team member should submit** the homework. If more than one version of the same homework is submitted by accident (submitted by more than one group member), please reach out to a tutor **as soon as possible**. Otherwise, the first submitted homework will be graded.*\n",
    "* *The submission must be in a Jupyter Notebook format (.ipynb). Submissions in **other formats will not be graded**.*\n",
    "* *It is not necessary to also submit the part of the exercise discussed by the tutor, please only submit the homework part.*\n",
    "* *If pictures need to be submitted, it is allowed to hand them in in a zip folder, together with the notebook. They should be added to the notebook like this: ``![example1](examplepicture1.PNG)`` (without apostrophs in a Markdown-Cell).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.1.</i> :::5 Homework points:::\n",
    "</div>\n",
    "\n",
    "The lexical ressource WordNet can also be used to calcualte the similarity between words.\n",
    "Use the predefined WuPalmer similarity measure in wordnet to score the similarity of each pair of words given in the code cell below. Rank the pairs in order of decreasing similarity. Print the ranked pairs as follows: *word1-word2 => score*. How close is your ranking to the order given in Miller & Charles, 1998, page 13? Discuss your results. The paper is given in moodle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that each word can have multiple synsets, which it is cointained in. For every word pair choose the corresponding pair of synsets, which maximaizes the similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = [\n",
    "    'car-automobile', 'gem-jewel', 'journey-voyage', 'boy-lad',\n",
    "    'coast-shore', 'asylum-madhouse', 'magician-wizard', 'midday-noon',\n",
    "    'furnace-stove', 'food-fruit', 'bird-cock', 'bird-crane', 'tool-implement',\n",
    "    'brother-monk', 'lad-brother', 'crane-implement', 'journey-car', 'monk-oracle',\n",
    "    'cemetery-woodland', 'food-rooster', 'coast-hill', 'forest-graveyard',\n",
    "    'shore-woodland', 'monk-slave', 'coast-forest', 'lad-wizard', 'chord-smile',\n",
    "    'glass-magician', 'rooster-voyage', 'noon-string'\n",
    "]\n",
    "\n",
    "# Example:\n",
    "# For demonstration the the first synset of each synset list is used.\n",
    "# This differs from task 5.1.\n",
    "s1 = wn.synsets(\"dog\",\"n\")[0]\n",
    "s2 = wn.synsets(\"cat\",\"n\")[0]\n",
    "s1.wup_similarity(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">5.2.</i> :::5 Homework points:::\n",
    "</div>\n",
    "\n",
    "Now use the pretrained word embeddings (google word2vec embeddings) to calculate the similarity of each word pair. Print your solution in the same way as in task 5.1. Compare your results with your previous results (5.1) and discuss possible differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
