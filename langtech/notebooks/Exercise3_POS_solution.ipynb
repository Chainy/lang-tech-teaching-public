{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Style des gesamten Dokuments */\n",
       "#notebook-container {\n",
       "\tfont-family: \"NimbusMonL-ReguObli\";\n",
       "\tfont-size: 120%\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r die Ãœberschrift: Zentriert diese und stellt sie fett dar. */\n",
       ".headline {\n",
       "\ttext-align: center;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 185.7%\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r die Aufgabenbeschreibung. Z.B.: \"Ãœbung zum Thema...\" */\n",
       ".description {\n",
       "\ttext-align: center;\n",
       "\tfont-size: 145.7%\n",
       "}\n",
       "\n",
       "/* Hebt das Abgabedatum fett und kursiv hervor */\n",
       "#submission {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r das eigentliche Thema. Z.B.: \"Intelligenz\" */\n",
       "#topic {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       ".task_description {\n",
       "\tmargin-bottom: 20px;\n",
       "}\n",
       "\n",
       "/* Hebt die Aufgabennummerierung fett hervor. */\n",
       ".task {\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 120%;\n",
       "\tborder-bottom: 2px solid black;\n",
       "  background-color: #97CAEF;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 50px;\n",
       "  padding-right: 50px;\n",
       "}\n",
       "\n",
       ".subtask {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #CAFAFE;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 25px;\n",
       "  padding-right: 25px;\n",
       "}\n",
       "\n",
       ".l1 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #14A76C;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l2 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FFE400;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l3 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FF652F;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".points {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       "ol.lower_roman {\n",
       "    list-style-type: lower-roman;\n",
       "}\n",
       "\n",
       "ol.characters {\n",
       "    list-style-type: lower-alpha;\n",
       "}\n",
       "\n",
       "/* Style einer Code-Cell */\n",
       ".CodeMirror-code {\n",
       "\tbackground-color: #ededed\n",
       "}\n",
       "\n",
       "/* Style eines Kommentars im Code Ã¤ndern. */\n",
       ".cm-s-ipython span.cm-comment {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-atom {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-number {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Keywords Ã¤ndern */\n",
       ".cm-s-ipython span.cm-keyword {\n",
       "\tcolor: #B000B0\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-def {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Python-Variable Ã¤ndern */\n",
       ".cm-s-ipython span.cm-variable {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Property Ã¤ndern */\n",
       ".cm-s-ipython span.cm-property {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Operators Ã¤ndern */\n",
       ".cm-s-ipython span.cm-operator {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Strings Ã¤ndern */\n",
       ".cm-s-ipython span.cm-string {\n",
       "\tcolor: brown;\n",
       "}\n",
       "\n",
       "/* Style einer eingebauten Funktion Ã¤ndern (z.B. \"open\") */\n",
       ".cm-s-ipython span.cm-builtin {\n",
       "\n",
       "}\n",
       "\n",
       "/* Hebt hervor, welche Klammern zueinander passen */\n",
       ".cm-s-ipython .CodeMirror-matchingbracket {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-variable-2 {\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2020/2021\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"Part-of-speech-tagging\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">Friday, 27.11.2020, (11:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.corpus import*\n",
    "from nltk.book import*\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Präsenzübung\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.1:</i> <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "Discuss which of the following concepts may be regarded as POS tags.\n",
    "1. word classes\n",
    "2. lexical categories\n",
    "3. verbs, nouns, adjectives\n",
    "4. present tense, past tense\n",
    "5. emotion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. True. POS tags are basically word classes.\n",
    "2. True, because lexical category is considered to be a synonym for word class.\n",
    "3. True, these word classes are standard POS.\n",
    "4. False. Some POS tagsets (e.g. Penn Treebank tagset) have subcategories for verbs that code tense but tense is not itself a part of speech.\n",
    "5. No, because “emotion” is not considered to be a word class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.2:</i> <br>\n",
    "</div>\n",
    "\n",
    "Which of the following statements are true? Find examples or counterexamples.\n",
    "1. Homographs may be used as synonyms.\n",
    "2. Homographs remain homographs regardless of their capitalization.\n",
    "3. Homographs belong to the same word class.\n",
    "4. Homographs have the same pronunciation.\n",
    "5. Homographs are spelled equally. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. False. Homographs have different meaning by definition, e.g. ’bat’ (an animal) vs ’bat’ (hitting instrument)\n",
    "2. False. As capitalization in English usually changes the meaning of a word, differently capitalized words are not considered to be spelled equally.\n",
    "3. Not necessarily. For example, the both words “bat” (an animal) and “bat” (hitting instrument) are nouns, while there also is the verb “bat” (strike with, or as if with a baseball bat) as in “bat the ball”.\n",
    "4. Not necessarily, e.g. for example “conflict” (verb) has an accent on the second syllable, while “conflict” (noun) has accent on the first syllable. If two homographs have the same pronunciation, they are called homonyms.\n",
    "5. True, by definition. Words with different spelling and same pronunciation are called homophones, for example too, two and to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.3:</i> <br>\n",
    "</div>\n",
    "\n",
    "N-gram tagging: Which of the following statements are true?\n",
    "\n",
    "1. A trigram tagger is theoretically more accurate than a bigram tagger.\n",
    "2. A trigram tagger looks at the current token and two preceding tags.\n",
    "3. At sentence boundaries, the bigram tagger takes the two tokens of the previous sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. Yes, in theory, a trigram tagger considers the context of three words to perform the tagging, which should be more accurate than considering only two words like the bigram tagger. However, in practice, the trigram tagger needs a very, very large training corpus to obtain reliable frequency estimates for all possible trigrams. Thus, the accuracy of a trigram tagger trained on a limited corpus might be worse than those of a bigram tagger. However, in practice, “backoff” is used. Thus, the trigram tagger falls back to the bigram tagger in situations where there is not enough training data for a certain trigram.\n",
    "2. True. However, it is also possible to consider both left and right context.\n",
    "3. False, because the tokens in the previous sentences do not help to identify a correct tag for the current token. Usually special tokens representing “Begin-of-Sentence” (BOS) are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.4:</i> <br>\n",
    "</div>\n",
    "\n",
    "Confusion matrix: Which of the following statements are true?\n",
    "1. The diagonal elements are always 1.\n",
    "2. Cell (i , j) contains the count of the number of times tag i were classified as tag j.\n",
    "3. The confusion matrix may be used to identify tagging problems.\n",
    "4. The confusion matrix may be used to compare different taggers.\n",
    "5. The number of rows is equal to the number of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. False, because the diagonal elements represent the correctly classified instances.\n",
    "2. Correct by the definition of the confusion matrix.\n",
    "3. True, because it helps us to determine how often some label i was wrongly tagged with a label j.\n",
    "4. True, because we may compare the number of errors produced by two taggers.\n",
    "5. True. cell[i, j] demonstrates how many labels i were assigned with a tag j, hence the number of horizontal and vertical rows is equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.5:</i> <br>\n",
    "</div>\n",
    "\n",
    "Given the sentence “The near future promises happiness for all students.”. Tag it manually (using universal tags) and explain which of the following clues were helpful:\n",
    "1. morphological clues\n",
    "2. syntactic clues\n",
    "3. semantic clues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. The suggested tagging is “The/DET near/ADJ future/NOUN promises/VERB happyness/NOUN for/ADP all/DET students/NOUN ./.”. Morphological clues are useful to determine the part-of-speech of happyness as word with the suffix “-ness” are usually nouns (there are some exceptions, e.g. “to witness”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "2. Syntactical clues are useful to disambiguate that future is a noun (it is found in a DET + ADJ + NOUN structure), while promises is a verb (it is found between two noun phrases).\n",
    "3. Semantic clues are not of much use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "pos_tag(word_tokenize(\"The near future promises happiness for all students.\"), tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.6:</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Many words, like “ski” and “race”, can be used as nouns or verbs with no difference in pronunciation. Can you think of others? <br> Hint: Think of a commonplace object and try to put the word “to” before it to see if it can also be a verb, or think of an action and try to put “the” before it to see if it can also be a noun. Now make up a sentence with both uses of this word, and run the POS-tagger from NLTK on this sentence (using the universal tagset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "The phenomenon when a verb becomes noun is called nominalization. Nominalization without any overt changes to the word (called \"conversion\") is very common in English. However, in other languages (for example Russian) verbs and nouns have different suffixes and this phenomenon is very rare. <br>Examples of English nominalized words are \"attack\" or \"sentence\". A recent example is “google” that is now used as a verb, too. <br>Example sentences and their part-of-speech (POS) tags obtained using\n",
    "nltk.pos_tag(nltk.word_tokenize(sentence), tagset=\"universal\")\n",
    " are given in the following table <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "sents = [\n",
    "    \"A bicyle race will be nice.\\nLet's race and see who gets there first.\",\n",
    "    \"His sentence was 5 to 10 years.\\n A judge will sentence him to ten years in prison.\",\n",
    "    \"Google is a search engine that searches for men.\\n She will google the man she had met at the party\"\n",
    "]\n",
    "\n",
    "for sent in sents:\n",
    "    tagged_sent = pos_tag(word_tokenize(sent), tagset=\"universal\")\n",
    "    print(sent, \"\\n\")\n",
    "    for word, tag in tagged_sent:\n",
    "        print(\"{} --> {}\\n\".format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "\n",
    "| words | POS   | Sentence | Parsed Sentence\n",
    "|------|------|------|-----\n",
    "|  race <br> race |noun <br> verb | A bicycle race will be nice <br> Let’s race and see who gets there first |[(’A’, ’DET’), (’bicycle’, ’ADJ’), (’race’, ’NOUN’), (’will’, ’VERB’), (’be’, ’VERB’), (’nice’, ’ADJ’)] <br> [(’Let’, ’VERB’), (“s\", ’PRT’), (’race’, ’NOUN’), (’and’, ’CONJ’), (’see’, ’VERB’), (’who’, ’PRON’), (’gets’, ’VERB’), (’there’, ’ADV’), (’first’, ’ADJ’)]\n",
    "| sentence <br> sentence | noun <br> verb | His sentence was 5 to 10 years. <br> A judge will sentence him to ten years in prison | [(’His’, ’PRON’), (’sentence’, ’NOUN’), (’was’, ’VERB’), (’5’, ’NUM’), (’to’, ’PRT’), (’10’, ’NUM’), (’years’, ’NOUN’), (’.’, ’.’)] <br> [(’A’, ’DET’), (’judge’, ’NOUN’), (’will’, ’VERB’), (’sentence’, ’VERB’), (’him’, ’PRON’), (’to’, ’PRT’), (’ten’, ’VERB’), (’years’, ’NOUN’), (’in’, ’ADP’), (’prison’, ’NOUN’), ('.', '.')]\n",
    "| google <br> google | noun <br> verb | Google is a search engine that searches for men. <br> She will google the man she had met at the party | [(’Google’, ’NOUN’), (’is’, ’VERB’), (’a’, ’DET’), (’search’, ’NOUN’), (’engine’, ’NOUN’), (’that’, ’DET’), (’searches’, ’VERB’), (’for’, ’ADP’), (’men’, ’NOUN’), (’.’, ’.’)] <br> [(’She’, ’PRON’), (’will’, ’VERB’), (’google’, ’VERB’), (’the’, ’DET’), (’man’, ’NOUN’), (’she’, ’PRON’), (’had’, ’VERB’), (’met’, ’VERB’), (’at’, ’ADP’), (’the’, ’DET’), (’party’, ’NOUN’)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "The verb “race” is incorrectly tagged as “NOUN” in the second sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.7:</i> <br>\n",
    "</div>\n",
    "\n",
    "Different words that have the same written form are called homographs. A simplified definition is that homographs are words with the same spelling (case sensitive) and different POS. <br><br>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.7.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the code cell below, what will be printed on the console if it is executed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_fd = nltk.FreqDist(tag\n",
    "                       for (word, tag) \n",
    "                       in brown.tagged_words(tagset='universal'))\n",
    "\n",
    "print(tag_fd.N())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "A frequency distribution of the tags found in the brown corpus will be build and\n",
    "the total amount of samples will be printed to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.7.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "As the code above is quite useless in its current form, it needs to be improved. Do so by changing it so that the output contains all POS tags (universal) that are used in a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "tag_fd = nltk.FreqDist(tag\n",
    "                       for (word, tag) \n",
    "                       in brown.tagged_words(tagset='universal'))\n",
    "\n",
    "print(tag_fd.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "For the Brown Corpus: DET,NOUN,ADJ,VERB,ADP,.,ADV,CONJ,PRT,PRON,NUM,X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.7.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Change the code again so that it finds all homographs (using the universal definition) within a corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "To see that we really use a simplification for homographs, type the word “bass” into www.leo.org and check the different meanings of the listed nouns. Solution code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist((word, tag)\n",
    "                               for word, tag\n",
    "                               in brown.tagged_words(tagset='universal'))\n",
    "\n",
    "homographs = [key for key in cfd.keys() if len(cfd[key]) > 1]\n",
    "\n",
    "for homograph in homographs:\n",
    "    print(\"{}\\n{}\\n\".format(homograph, cfd[homograph].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.8:</i> <br>\n",
    "</div>\n",
    "\n",
    "Write programs to process the Brown Corpus and find answers to the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "What is the output of the code below? Proof your answer by executing it on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FreqDist(word \n",
    "              for (word,tag) \n",
    "              in brown.tagged_words(tagset='universal')\n",
    "              if tag == 'NOUN')\n",
    "\n",
    "fd.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "The code prints each token from the corpus that is tagged as a noun in the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different corpora don't necessarily employ the same tagset. In the following we will inspect the brown corpus and its original tagset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "What are the 10 most frequent tags in the Brown Corpus using the original Brown tagset (instead of the universal tagset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "tag_fd_br = FreqDist(tag \n",
    "                     for (word, tag) \n",
    "                     in brown.tagged_words())\n",
    "\n",
    "tag_fd_br.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.3</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "What do these tags stand for? Print 10 example words for each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "for (freq_tag, _) in tag_fd_br.most_common(10):\n",
    "    fd_word_br = FreqDist(word \n",
    "                          for (word, tag)\n",
    "                          in brown.tagged_words()\n",
    "                          if freq_tag == tag)\n",
    "    \n",
    "    print(\"{} example words\\n{}\"\n",
    "          .format(freq_tag, [word for (word, _) in fd_word_br.most_common(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.4</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Change the code from task 3.8.1 so that the output contains the 5 most frequent singular and the 5 most frequent plural nouns from the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fd_n = FreqDist(word \n",
    "                for (word,tag) \n",
    "                in brown.tagged_words() \n",
    "                if tag == 'NN')\n",
    "\n",
    "fd_ns = FreqDist(word\n",
    "                 for (word,tag)\n",
    "                 in brown.tagged_words()\n",
    "                 if tag == 'NNS')\n",
    "\n",
    "print (\"Singular:\", fd_n.most_common(5))\n",
    "print (\"Singular:\", fd_ns.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "\n",
    "For the Brown Corpus, the output is: Singular: [time, man, Af, way, world], Plural: [years, people, men, States, eyes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.5</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Which nouns are more common in their plural form, rather than their singular form? Change the code again to find out! (Only consider regular plurals, formed with the -s suffix.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "Refer to the code in the following listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "corpus = brown.tagged_words()\n",
    "fdist_sg = nltk.FreqDist(word \n",
    "                         for (word,tag) \n",
    "                         in corpus \n",
    "                         if tag == 'NN')\n",
    "\n",
    "fdist_pl = nltk.FreqDist(word\n",
    "                         for (word,tag) \n",
    "                         in corpus \n",
    "                         if tag == 'NNS' and word[-1] == \"s\")\n",
    "\n",
    "for word in fdist_pl.keys():\n",
    "    if fdist_pl[word] > fdist_sg[word[:-1]]:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.9:</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "In the Brown corpus, what percentage of words are tagged with the first five most common original tags?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "tag_fd = nltk.FreqDist(tag\n",
    "                       for (word, tag) \n",
    "                       in brown.tagged_words())\n",
    "\n",
    "s = 0\n",
    "for i in tag_fd.most_common(5):\n",
    "    s += i[1]\n",
    "    \n",
    "print(s / tag_fd.N())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "The first five tags cover about 43% of all tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.10:</i> <br>\n",
    "</div>\n",
    "\n",
    "Generate some statistics for tagged data to answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.10.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "Take a look at the code below. What does it compute? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = ConditionalFreqDist((word.lower(), tag) \n",
    "                          for (word, tag) \n",
    "                          in brown.tagged_words())\n",
    "\n",
    "nr_tags_cfd = ConditionalFreqDist((len(cfd[word]), word) \n",
    "                                  for word\n",
    "                                  in cfd.conditions())\n",
    "\n",
    "nr_of_tags = 1\n",
    "print(\"words with one tag:\", len(nr_tags_cfd[nr_of_tags]))\n",
    "print(\"ratio:\", len(nr_tags_cfd[nr_of_tags]) / len(cfd.conditions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "The Code computes the proportion of how many word types are always assigned the same POS tag. For the Brown corpus, there are 40235 types that appear with only one (non-universal) POS-tag. This are 81% of all word types in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.10.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "How many words are ambiguous, in the sense that they appear with at least two tags (no programming required)? Change the code above so that it computes the percentage of word tokens that involve these ambiguous words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist((word.lower(),tag) \n",
    "                               for (word, tag) \n",
    "                               in brown.tagged_words())\n",
    "\n",
    "nr_tags_cfd = nltk.FreqDist(len(cfd[word])\n",
    "                            for word \n",
    "                            in brown.words())\n",
    "\n",
    "print(\"ambigious words:\", len(brown.words()) - nr_tags_cfd[1])\n",
    "print(\"ratio:\", float(1-nr_tags_cfd[1]/len(brown.words())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "19% of the words in the corpus are ambiguous (can simply induced from 3.10.1 without any programming). The overall ratio of ambiguous tokens in the Brown Corpus is 87%. This means that a small amount of 19% ambiguous types correspond to a large number of ambiguous tokens. It is a known linguistic phenomenon that frequent words are more ambiguous than seldom occurring words (see Zipf distribution in lecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.10.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Which words in the Brown corpus have the highest number of distinct tags?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cfd = ConditionalFreqDist((word.lower(), tag)\n",
    "                          for (word, tag) \n",
    "                          in brown.tagged_words())\n",
    "\n",
    "nr_tags_cfd = ConditionalFreqDist((len(cfd[word]), word)\n",
    "                                  for word\n",
    "                                  in cfd.conditions())\n",
    "\n",
    "highest_nr_tags = max(nr_tags_cfd.conditions())\n",
    "print(\"Highest # of tags:\", highest_nr_tags)\n",
    "print(\"Words with\",\n",
    "      highest_nr_tags, \"tags:\",\n",
    "      ', '.join(nr_tags_cfd[highest_nr_tags].keys()))\n",
    "\n",
    "for word in nr_tags_cfd[highest_nr_tags].keys():\n",
    "    print (word, \"-->\", ' '.join(cfd[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "The highest number of tags is 15. There is one word with 15 different tags: that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.11:</i> <br>\n",
    "</div>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.11.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Look at the code below, explain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_sentence():\n",
    "    #TODO\n",
    "    pass\n",
    "\n",
    "def get_most_likely_tag():\n",
    "    #TODO\n",
    "    pass\n",
    "\n",
    "word_tag_cfd = nltk.ConditionalFreqDist((word.lower(), tag) \n",
    "                                        for (word, tag) \n",
    "                                        in brown.tagged_words(tagset='universal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "A conditional frequency distribution ”word_tag_cfd” is created, that includes each word of the brown corpus together with the universal tag of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.11.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "We now want to give the code a little bit more functionality. As you can see, the function get_a_sentence is called, but at the moment, it will not do anything. Enhance it so that when called, it will print out each token of a sentence in the Brown corpus (Hint: get_a_sentence(40) will return sentence number 41, not 40)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def get_a_sentence(nr):\n",
    "    x = brown.tagged_sents(tagset='universal')[nr]\n",
    "    for i in x:\n",
    "        print (i[0])\n",
    "        \n",
    "def get_most_likely_tag():\n",
    "    pass\n",
    "    #TODO\n",
    "    \n",
    "word_tag_cfd = nltk.ConditionalFreqDist((word.lower(), tag) \n",
    "                                        for (word, tag) \n",
    "                                        in brown.tagged_words(tagset ='universal'))\n",
    "    \n",
    "get_a_sentence(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "For sentence 41:\n",
    "Hartsfield has\n",
    "been mayor\n",
    "of Atlanta\n",
    ",\n",
    "with exception of\n",
    "one\n",
    "brief interlude ,\n",
    "since 1937\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.11.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "We now want the tag for each token of the sentence. Enhance the function get_most_likely_tag so that the most likely tag for a token is returned (use the word_tag_cfd as a lookup dictionary and test your method on a sentence from the Brown corpus).\n",
    "Then change the function get_a_sentence again so that not only each token, but also the tag of the token is printed out in the console.\n",
    "Test your function on a sentence from the Moby Dick corpus. How well does it perform? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def get_a_sentence(s):\n",
    "    for w in s:\n",
    "        print(w,'-',get_most_likely_tag(w, word_tag_cfd))\n",
    "        \n",
    "def get_most_likely_tag(word, lookup_cfd):\n",
    "    tag = 'UNK'\n",
    "    if word in lookup_cfd.conditions():\n",
    "        tag = lookup_cfd[word].max()\n",
    "    return tag\n",
    "\n",
    "\n",
    "word_tag_cfd = ConditionalFreqDist((word, tag)\n",
    "                                   for (word, tag) \n",
    "                                   in brown.tagged_words(tagset='universal'))\n",
    "\n",
    "print(\"Brown: \", get_a_sentence(brown.sents()[40]))\n",
    "print(\"Moby: \",  get_a_sentence(text1[42:73]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "Several tokens from the Moby Dick corpus have no tag assigned to them (marked with UNK), as they did not appear in the data used for training the tagger (Brown corpus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.12:</i> <br>\n",
    "</div>\n",
    "\n",
    "Explore the n-gram taggers for n ∈ 1, 2, 3 in the following listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NOUN')\n",
    "train_sents = brown.tagged_sents(tagset='universal')\n",
    "t1 = nltk.UnigramTagger(train_sents)\n",
    "t2 = nltk.BigramTagger(train_sents)\n",
    "t3 = nltk.TrigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.12.1</i><br>\n",
    "</div>\n",
    "\n",
    "Manually tag the sentence “The only conservative councillor representing Cambridge resigned from the city council.” using the universal tagset. Represent it as a tagged sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "|Word|Correct\n",
    "|-|-\n",
    "|The|DET\n",
    "|only | ADJ\n",
    "|conservative |ADJ\n",
    "|councillor |NOUN\n",
    "|representing |VERB\n",
    "|Cambridge | NOUN\n",
    "|resigned| VERB\n",
    "|from |ADP\n",
    "|the| DET\n",
    "|city |NOUN\n",
    "|council|NOUN\n",
    "|.|.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.12.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "We now want to evaluate the performance of different n gram taggers. Enhance the the code using the function tagger.evaluate(sentences) so that all four taggers are evaluated on the sentence from task 3.12.1 The default tagger is already implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "sentence = [\n",
    "    'The', 'only', 'conservative',\n",
    "    'councillor', 'representing', 'Cambridge',\n",
    "    'resigned', 'from', 'the',\n",
    "    'city' , 'council' , '.'\n",
    "]\n",
    "\n",
    "tagged_sentence = [\n",
    "    ('The', 'DET'), ('only', 'ADJ'), ('conservative','ADJ'),\n",
    "    ('councillor','NOUN'), ('representing','VERB'), ('Cambridge','NOUN'),\n",
    "    ( 'resigned','VERB'), ( 'from','ADP'), ('the','DET'),\n",
    "    ('city','NOUN'), ('council','NOUN') , ( '.','.')\n",
    "]\n",
    "\n",
    "                                 \n",
    "print(t0.tag(sentence))\n",
    "print(t0.evaluate([tagged_sentence]))\n",
    "print(t1.tag(sentence))\n",
    "print(t1.evaluate([tagged_sentence]))\n",
    "print(t2.tag(sentence))\n",
    "print(t2.evaluate([tagged_sentence]))\n",
    "print(t3.tag(sentence))\n",
    "print(t3.evaluate([tagged_sentence])                                 )\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "Most of the bigrams and trigrams in the sentence are not found in the corpus. Thus, the performance of the n-gram taggers decreases with increasing n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.12.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "The idea of backoff tagging is to rely on other taggers when the current tagger cannot assign a label. For example, a bigram tagger might never encounter some bigram, however a unigram tagger may separately tag the single words in the bigrams. In this task, we will explore the contribution of n-gram taggers for n ∈ 1, 2, 3 in the backoff setup, provided by the following listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NOUN')\n",
    "train_sents = brown.tagged_sents(tagset='universal')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff = t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff = t1)\n",
    "t3 = nltk.TrigramTagger(train_sents, backoff = t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the sentence “The only Conservative councillor representing Cambridge resigned from the city council.“ using the taggers t0, t1, t2, and t3 with backoff tagging and evaluate the results like in task 3.12.2). Compare the results with and without backoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(t0.tag(sentence))\n",
    "print(t0.evaluate([tagged_sentence]))\n",
    "print(t1.tag(sentence))\n",
    "print(t1.evaluate([tagged_sentence]))\n",
    "print(t2.tag(sentence))\n",
    "print(t2.evaluate([tagged_sentence]))\n",
    "print(t3.tag(sentence))\n",
    "print(t3.evaluate([tagged_sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "The performance of the default tagger is unchanged, as it is as dumb as before :) The unigram tagger improves a little bit, as in case of unknown words it can now backoff to the default tagger. As the probability that unseen words are nouns is quite high, this gives some improvements. The bigram tagger improves dramatically, as it backs off to the unigram tagger when it cannot recognize a bigram. The behavior of the trigram tagger is identical to the bigram tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Submission guidelines*\n",
    "* *The submission has to be done by a team of two people. **Individual submissions will not be graded**.*\n",
    "* *Please state the **name and matriculation number of all team members** in every submission **clearly**.*\n",
    "* *Only **one team member should submit** the homework. If more than one version of the same homework is submitted by accident (submitted by more than one group member), please reach out to a tutor **as soon as possible**. Otherwise, the first submitted homework will be graded.*\n",
    "* *The submission must be in a Jupyter Notebook format (.ipynb). Submissions in **other formats will not be graded**.*\n",
    "* *It is not necessary to also submit the part of the exercise discussed by the tutor, please only submit the homework part.*\n",
    "* *If pictures need to be submitted, it is allowed to hand them in in a zip folder, together with the notebook. They should be added to the notebook like this: ``![example1](examplepicture1.PNG)`` (without apostrophs in a Markdown-Cell).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 3.1:</i>\n",
    "        ::: 5 Homework points :::</div>\n",
    "                                \n",
    "Write code to search the Brown Corpus for particular words and phrases according to tags (universal tagset), to answer the following questions: <br><br>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.1.1</i>\n",
    "</div>\n",
    "Produce an alphabetically sorted list of the distinct words tagged as ADP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.1.2</i>\n",
    "</div>\n",
    "\n",
    "Identify words that can be plural nouns or third person singular verbs (e.g. deals, flies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.1.3</i>\n",
    "</div>\n",
    "\n",
    "For the word(s) with the greatest number of distinct tags, print the sentences from the corpus containing the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.1.4</i>\n",
    "</div>\n",
    "\n",
    "What is the ratio of masculine to feminine pronouns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 3.2:</i>\n",
    "        ::: 5 Homework points :::</div>\n",
    "        \n",
    "\n",
    "Print a table with the integers 1..10 in one column, and the number of types in the corpus having 1..10 distinct tags in the other column."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
