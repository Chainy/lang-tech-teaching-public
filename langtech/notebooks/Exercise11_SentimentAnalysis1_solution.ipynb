{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.core.display import HTML\n", "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"headline\">\n", "Language Technology / Sprachtechnologie\n", "<br><br>\n", "Wintersemester 2020/2021\n", "</div>\n", "<br>\n", "<div class=\"description\">\n", "    \u00dcbung zum Thema <i id=\"topic\">\"Sentiment Analysis\"</i>\n", "    <br><br>\n", "    Deadline Abgabe: <i #id=\"submission\">none (see part 2)</i>\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "pd.set_option('display.max_colwidth', None)  \n", "import matplotlib.pyplot as plt\n", "from os.path import join\n", "import nltk\n", "%matplotlib inline  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Pr\u00e4senz\u00fcbung"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Warm-Up"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Sentiment Lexicons"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "    <i class=\"task\">Task 11.1:</i> <br>\n", "</div>\n", "\n", "Which statements are true?\n", "\n", "1. Subjective sentences generally refer to a personal opinion, emotion or judgment, whereas objective refers to factual information.\n", "2. Polarity denotes the orientation of the opinion expressed into positive and negative (and in some cases neutral). \n", "3. Sentiment analysis is a technique to recognize the polarity of a text opinion (positive, negative, neutral, both)."]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>\n", "1. True\n", "2. True\n", "3. True"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Working with SentiWordNet"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "    <i class=\"task\">Task 11.2:</i> <i class=\"l2\">L2</i> <br><br>\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculate the polarity scores (positive, negative, neutral scores) for the following lexicons using nltk SentiWordnet.\n", "\n", "1. Happy\n", "2. Sad\n", "3. Awesome\n", "4. Joy\n", "5. Fearless"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nltk\n", "nltk.download('sentiwordnet')\n", "from nltk.corpus import sentiwordnet as swn\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["happy: "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["list(swn.senti_synsets('happy'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["happy = swn.senti_synset('happy.a.01')\n", "\n", "print(happy.pos_score())\n", "print(happy.neg_score())\n", "print(happy.obj_score())"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["sad: "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["print(swn.senti_synset('sad.a.01').pos_score())\n", "print(swn.senti_synset('sad.a.01').neg_score())\n", "print(swn.senti_synset('sad.a.01').obj_score())"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["awesome: "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["print(swn.senti_synset('awesome.a.01').pos_score())\n", "print(swn.senti_synset('awesome.a.01').neg_score())\n", "print(swn.senti_synset('awesome.a.01').obj_score())"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["joy: "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["list(swn.senti_synsets('joy'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["print(swn.senti_synset('joy.n.01').pos_score())\n", "print(swn.senti_synset('joy.n.01').neg_score())\n", "print(swn.senti_synset('joy.n.01').obj_score())"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["fearless: "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["list(swn.senti_synsets('fearless'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["print(swn.senti_synset('unafraid.a.01').pos_score())\n", "print(swn.senti_synset('unafraid.a.01').neg_score())\n", "print(swn.senti_synset('unafraid.a.01').obj_score())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Working with the Amazon sentiment dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.3.1</i> <i class=\"l1\">L1</i> <br>\n", "</div>\n", "\n", "Run the following code-snippet. Explain it."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(join('data', 'amazon_reviews_sentiments.tsv'), names=['Statement', 'label'], sep='\\t')\n", "print(df.shape)\n", "df.head(10)"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>\n", "\n", "1. Creating pandas dataframe with column name \"Statement\" and \"label\" (0 is negative sentiment and 1 is positive sentiment) with tab as demiliter. \n", "2. Displaying shape and the first 10 rows of the dataframe."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.3.2</i> <i class=\"l2\">L2</i> <br>\n", "</div>\n", "\n", "Run the following code-snippet. Explain it. <br> Also analyse the distribution (check whether it is uniform or not)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import seaborn as sns\n", "sns.countplot(x=\"label\", data=df)"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>\n", "\n", "1. Displaying label distribution of the dataset. \n", "2. Analysis: both labels are equally distributed "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.3.3</i> <i class=\"l2\">L2</i> <br>\n", "</div>\n", "\n", "Explain the following code snippet. Also analyse the results and provide comments.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.corpus import stopwords\n", "from nltk.probability import FreqDist\n", "\n", "statements = df[\"Statement\"]\n", "\n", "\n", "stops_eng = stopwords.words('english')\n", "fd = FreqDist()\n", "for statement in statements:\n", "    words = statement.split(\" \")\n", "    for word in words:\n", "        if word.lower() not in stops_eng:\n", "            if word.isalpha():\n", "                fd[word.lower()] += 1\n", "    \n", "    \n", "vocab = fd.keys()\n", "plt.figure(figsize=(16,5))\n", "fd.plot(20)"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>\n", "\n", "Displaying frequency distribution curve for the first 20 most frequent terms available in the statements (excluding stopwords). "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.3.4</i> <i class=\"l2\">L2</i> <br>\n", "</div>\n", "\n", "Repeat the above frequency distribution only for positive and negative sentiment statements. <br>Compare both distributions and describe your observation. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["positive_sent_stmts = df.loc[df['label'] == 1]['Statement']\n", "negative_sent_stmts = df.loc[df['label'] == 0]['Statement']\n", "\n", "# TODO"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["positive_sent_stmts = df.loc[df['label'] == 1]['Statement']"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["positive_sent_stmts.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["fd_pos = FreqDist()\n", "for statement in positive_sent_stmts:\n", "    words = statement.split(\" \")\n", "    for word in words:\n", "        if word.lower() not in stops_eng:\n", "            if word.isalpha():\n", "                fd_pos[word.lower()] += 1\n", "vocab = fd_pos.keys()\n", "print(len(vocab))\n", "print(fd_pos.most_common(20))\n", "plt.figure(figsize=(16,5))\n", "fd_pos.plot(20)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["negative_sent_stmts = df.loc[df['label'] == 0]['Statement']"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["negative_sent_stmts.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["fd_neg = FreqDist()\n", "for statement in negative_sent_stmts:\n", "    words = statement.split(\" \")\n", "    for word in words:\n", "        if word.lower() not in stops_eng:\n", "            if word.isalpha():\n", "                fd_neg[word.lower()] += 1\n", "vocab = fd_neg.keys()\n", "print(len(vocab))\n", "print(fd_neg.most_common(20))\n", "plt.figure(figsize=(16,5))\n", "fd_neg.plot(20) # common terms like battery, works, good are equally distrbuted in neg and pos statements \n", "# getting words like nice, best, love in positive statements where as waste, bad in negative statements"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Using sentiment lexicons"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "    <i class=\"task\">Task 11.4:</i> \n", "</div>\n", "\n", "Use existing lexical resources and machine learning algorithms to generate the classifier and test it on a separate held out set. Compare their performance. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.4.1</i> <i class=\"l2\">L2</i> <br>\n", "</div>\n", "\n", "Split the dataset into train and test set (use the last 200 records for the test set)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["labels = df[\"label\"]\n", "train_statements =  #TODO\n", "train_labels = #TODO\n", "test_statements = #TODO\n", "test_labels = #TODO"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["labels = df[\"label\"]\n", "print(labels[:10])"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["train_statements = statements[:-200]\n", "train_labels = labels[:-200]\n", "test_statements = statements[-200:]\n", "test_labels = labels[-200:]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.4.1</i> <i class=\"l2\">L2</i> <br>\n", "</div>\n", "\n", "Download the sentiment lexicons list from <br><br> \n", "https://hlt-nlp.fbk.eu/technologies/sentiwords <br><br> \n", "You need to fill out the form to download the list and create a python dictonary which holds lexicons as key and sentiment score as value. <br>\n", " *Note*: the sentiment score will vary from -1 to 1 (negative sentiment to positive sentiment).\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import codecs\n", "\n", "senti_dict = {}\n", "with codecs.open('SentiWords_1.1.txt', 'r', 'utf-8') as senti_words:\n", "    #TODO"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["import codecs\n", "\n", "senti_dict = {}\n", "with codecs.open('SentiWords_1.1.txt', 'r', 'utf-8') as senti_words:\n", "    for line in senti_words:\n", "        if line[0] != '#':\n", "            senti_dict[line.split('\\t')[0].split('#')[0]] =  float(line.split('\\t')[1].strip().rstrip('\\r').replace('\\n',''))     "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["print(*list(senti_dict.items())[:10], sep=\"\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.4.2</i> <i class=\"l2\">L2</i> <br>\n", "</div>\n", "\n", "Explain the following code and analyse the result."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lexicon_senti_scores= []\n", "for stmt in test_statements:\n", "    senti_pred = []\n", "    for w in nltk.word_tokenize(stmt):\n", "        if w.lower() in senti_dict.keys():\n", "            # print(senti_dict[w.lower()],end=\" \")\n", "            senti_pred.append(senti_dict[w.lower()])\n", "        else:\n", "            senti_pred.append(0.0)\n", "    lexicon_senti_scores.append(np.sum(np.array(senti_pred)))"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>\n", "\n", "* Calculating the average sentiment scores for each of the test statements\n", "* If the average score of all words available in the sentence is greater than 0 it is classified as positive sentiment\n", "* If it is less than 0 classify it as negative sentence. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.4.3</i> <i class=\"l3\">L3</i> <br>\n", "</div>\n", "\n", "Convert average scores into prediction scores: <br>\n", "* Use a prediction score of 1 if the average sentiment score is greater than 0 \n", "* use 0 if the sentiment score is less than 0\n", "* else use 2. <br><br>\n", "Print the first ten rows."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lexicon_senti_pred = []\n", "\n", "for score in lexicon_senti_scores:\n", "    # TODO"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["lexicon_senti_pred = []\n", "\n", "for score in lexicon_senti_scores:\n", "    if score > 0:\n", "        lexicon_senti_pred.append(1)\n", "    elif score <= 0:\n", "        lexicon_senti_pred.append(0)\n", "    else:\n", "        lexicon_senti_pred.append(2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["for i in range(10):\n", "    print(\"%s,%s,%s\" %(test_statements.values[i], test_labels.values[i], lexicon_senti_pred[i]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.4.4</i> <i class=\"l3\">L3</i> <br>\n", "</div>\n", "\n", "Determine the confusion matrix, accuracy score and classification report based on prediction and gold labels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n", "\n", "print(confusion_matrix(#TODO))\n", "print(accuracy_score(#TODO))\n", "print(classification_report(#TODO))"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n", "\n", "cf = confusion_matrix(test_labels.values, lexicon_senti_pred)\n", "print(cf)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["sns.heatmap(cf, cmap=\"GnBu\", annot=True, fmt='g');"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["accuracy_score(test_labels.values,lexicon_senti_pred) "]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["solution"]}, "outputs": [], "source": ["print(classification_report(test_labels.values, lexicon_senti_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"task_description\">\n", "   <i class=\"subtask\">11.4.5</i> <i class=\"l3\">L3</i> <br>\n", "</div>\n", "\n", "Find three statements that the classifier fails. <br>\n", "Please run the following code to test the classifier and give a justification for the classifier failure. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Process user input. Processing continues until the user says goodbye. \n", "text = \"\"\n", "while text != \"goodbye\":\n", "    # Read user input\n", "    text = input()\n", "    prediction_score = []\n", "    for word in text.split(' '):\n", "        if word.lower() in senti_dict.keys():\n", "            prediction_score.append(senti_dict[word.lower()])\n", "        else:\n", "            prediction_score.append(0.0)\n", "    if np.mean(prediction_score) > 0:\n", "        predition = \"Positive Sentiment\"\n", "    elif np.mean(prediction_score) < 0:\n", "        predition = \"Negative sentiment\"\n", "    else:\n", "        predition = \"Neutral\"\n", "    \n", "    print(predition)"]}, {"cell_type": "markdown", "metadata": {"tags": ["solution"]}, "source": ["<strong style=\"color: blue\">L\u00f6sung:</strong>\n", "\n", "I am not sad \u2013\u2013 *not* was not detected\n", "\n", "this ain't going to work \u2013\u2013 *n't* was not detected\n", "\n", "I barely like the product \u2013\u2013 *barely* not detected"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "nlp-env", "language": "python", "name": "nlp-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.6"}, "varInspector": {"cols": {"lenName": 16, "lenType": 16, "lenVar": 40}, "kernels_config": {"python": {"delete_cmd_postfix": "", "delete_cmd_prefix": "del ", "library": "var_list.py", "varRefreshCmd": "print(var_dic_list())"}, "r": {"delete_cmd_postfix": ") ", "delete_cmd_prefix": "rm(", "library": "var_list.r", "varRefreshCmd": "cat(var_dic_list()) "}}, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "window_display": false}}, "nbformat": 4, "nbformat_minor": 2}